# Medical Bot with Advanced RAG Pipeline üè• ü§ñ

An intelligent medical information retrieval system that combines advanced RAG (Retrieval-Augmented Generation) pipeline with comprehensive medical document analysis capabilities.


## üåü Features

- **Advanced RAG Pipeline**
  - Context-aware information retrieval and chuncking
  - Hybrid Semantic search capabilities
  - Dynamic document ranking
  - Query routing

- **Medical Document Analysis**
  - Insight generation 
  - Diagnosis and recommendations
  - Metadata extraction and organization

**Retriever-Augmented Generation** (RAG) is a technique that enhances the quality and relevance of generated text by incorporating a retriever. The retriever selects the most pertinent context from external documents, which then informs the generation process. This approach is valuable for producing accurate and contextually relevant responses, as it provides the model with focused context from external sources.

---

## Building a RAG-Powered Chatbot

In this section, we demonstrate how to build a chatbot using RAG to answer questions based on a given context. We‚Äôll use **Ollama models** and **embeddings** to create a simple Streamlit app capable of answering questions based on context ingested in a vector store database.

# Docker Image Documentation

## Overview

This Docker image provides a containerized version of the `medbot` application, ready to run in any environment that supports Docker.

The Docker image includes everything needed to run the app, including the necessary libraries and dependencies. This image is designed to work for anyone needing to deploy the app in a consistent and isolated environment.

## Prerequisites

Before using the image, make sure you have the following:

- Docker installed on your system.
- Access to Docker Hub or the ability to pull from a private registry.

## How to Pull the Image

To download or "pull" the image from Docker Hub, use the following command:

```bash
docker pull ion780/medbot:latest
```
Once the image is pulled, you can start a container from it. Here‚Äôs how to do it:

```bash
docker run -d -p 8501:8501 --name myapp-container ion780/medbot:latest
```
## Ollama

Ollama is a library built on top of the Hugging Face Transformers library, offering an easy way to implement Retriever-Augmented Generation (RAG) in projects. With a simple API, Ollama enables seamless integration of any retriever and generator model from the Hugging Face model hub. 

You can download Ollama from its [official website](https://ollama.com/).

---

## Getting started:
In order to run this app we need to install first our requirements dependencies using pip, to do that make sure to use the code below:
```bash
# Clone the repository
git clone https://github.com/el-Badr07/medical-bot

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt

cd MED-BOT

# Run the application
streamlit run LLM.py.py
```

## üìö Documentation

Comprehensive documentation is available at [medical-bot.readthedocs.io](https://medical-bot.readthedocs.io/)


Project Link: [https://github.com/el-Badr07/medical-bot]

## üó∫Ô∏è Feature improvements

- [ ] Add support for medical imaging analysis with vlms
- [ ] Implement some agents to help the retrieval and context refinement
- [ ] Generalise the pipeline to multiple fields
- [ ] Add audio input and multilanguage support
